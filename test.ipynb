{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488dc7df-3d4a-4b8d-b9c6-c9ea8493991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbce3f7f-0a01-4a88-95bd-683d8dcbfca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4736e5-4463-4539-8e0f-d03b32a440ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c89f552d31b4865ad4bdf95c54f430f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-VL-3B-Instruct\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    offload_buffers=True,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5db7b0b8-09b3-4a61-a686-9450848f693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Explain what overfitting is in one paragraph.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e33cd3-e4d1-4e0a-bb0f-628b21ea59b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[151644,\n",
       "  8948,\n",
       "  198,\n",
       "  2610,\n",
       "  525,\n",
       "  264,\n",
       "  10950,\n",
       "  17847,\n",
       "  13,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  840,\n",
       "  20772,\n",
       "  1128,\n",
       "  916,\n",
       "  6276,\n",
       "  1280,\n",
       "  374,\n",
       "  304,\n",
       "  825,\n",
       "  14311,\n",
       "  13,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4fd915f-a207-48be-b7f8-52b95924e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting occurs when a machine learning model learns the training data too well, to the point where it performs poorly on new, unseen data. This happens because\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Explain what overfitting is in one paragraph.\n",
      "assistant\n",
      "Overfitting occurs when a machine learning model learns the training data too well,\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=32,\n",
    "        streamer=streamer\n",
    "    )\n",
    "\n",
    "result = processor.decode(output[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f89eb-5bdf-4070-ad67-b5bb765e766b",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af4c763-905e-42e0-8afd-3c07544aa500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_rows(dataset_path: str) -> int:\n",
    "    return 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9164a125-af54-428d-b12f-d4c375123db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = {\n",
    "    \"count_rows\": count_rows\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c95037-2ea8-45f5-a215-e843ada53639",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a data analysis assistant.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "count_rows(dataset_path: string) -> int\n",
    "  Use when the user asks about the number of rows in a CSV dataset.\n",
    "\n",
    "Rules:\n",
    "- If a tool is required, respond ONLY with valid JSON\n",
    "- JSON format:\n",
    "{\n",
    "  \"tool\": \"<tool_name>\",\n",
    "  \"arguments\": { ... }\n",
    "}\n",
    "- If no tool is needed, respond:\n",
    "{\n",
    "  \"tool\": null,\n",
    "  \"answer\": \"<final answer>\"\n",
    "}\n",
    "- Do NOT explain your reasoning\n",
    "- Do NOT add extra text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdae4e0a-699a-415e-8a2e-99f3712117b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tool\": \"count_rows\",\n",
      "  \"arguments\": {\n",
      "    \"dataset_path\": \"dataset.csv\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": SYSTEM_PROMPT}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"How many rows are in dataset.csv?\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    text=prompt,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(\n",
    "    processor.tokenizer,\n",
    "    skip_prompt=True,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        streamer=streamer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9eb08ff1-86df-488d-9ba9-762b4151bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1660feac-cf06-4ecc-a76f-8a6a54c16e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tool\": \"count_rows\",\n",
      "  \"arguments\": {\n",
      "    \"dataset_path\": \"dataset.csv\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "generated_tokens = output[0][prompt_len:]\n",
    "\n",
    "result = processor.decode(\n",
    "    generated_tokens,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c808472-1f92-410a-b8b7-d5351f95f5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL RESULT: 11\n"
     ]
    }
   ],
   "source": [
    "tool_call = json.loads(result)\n",
    "\n",
    "tool_name = tool_call[\"tool\"]\n",
    "args = tool_call[\"arguments\"]\n",
    "\n",
    "result = TOOLS[tool_name](**args)\n",
    "print(\"TOOL RESULT:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fd3baa4-5fea-4a09-a48f-ec5c0fe39880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265b8d4-ab46-4864-b76c-5c24b4e13c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
